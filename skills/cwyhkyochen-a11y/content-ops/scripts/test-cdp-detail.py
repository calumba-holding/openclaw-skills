#!/usr/bin/env python3
"""
ä½¿ç”¨ redbookskills è·å–ç¬”è®°è¯¦æƒ…
é€šè¿‡ Chrome DevTools Protocol (CDP)
"""

import sys
import os
import json
import time

# æ·»åŠ  redbookskills åˆ°è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
REDBOOK_DIR = os.path.join(os.path.dirname(SCRIPT_DIR), 'redbookskills', 'scripts')
sys.path.insert(0, REDBOOK_DIR)

from feed_explorer import FeedExplorer, FeedExplorerError

def get_feed_detail_via_cdp(feed_id, xsec_token):
    """ä½¿ç”¨ CDP è·å–ç¬”è®°è¯¦æƒ…"""
    
    print(f"ğŸ” è·å–ç¬”è®°è¯¦æƒ…: {feed_id[:20]}...")
    print(f"   xsec_token: {xsec_token[:30]}...")
    
    # æ„å»ºè¯¦æƒ…é¡µ URL
    detail_url = f"https://www.xiaohongshu.com/explore/{feed_id}?xsec_token={xsec_token}&xsec_source=pc_search"
    
    print(f"   URL: {detail_url[:80]}...")
    
    try:
        # åˆ›å»º FeedExplorer å®ä¾‹ (ä½¿ç”¨ CDP)
        explorer = FeedExplorer(
            host="127.0.0.1",
            port=9222,
            headless=True,  # æ— å¤´æ¨¡å¼
            reuse_tab=True
        )
        
        print("   ğŸŒ è¿æ¥åˆ° Chrome...")
        explorer.connect()
        
        print("   ğŸ“„ åŠ è½½è¯¦æƒ…é¡µ...")
        explorer.navigate_to_detail(feed_id, xsec_token)
        
        print("   ğŸ“Š æå–æ•°æ®...")
        detail = explorer.get_feed_detail(feed_id)
        
        print("   âœ… æˆåŠŸè·å–!")
        
        # æå–å…³é”®ä¿¡æ¯
        title = detail.get('title', '')
        desc = detail.get('desc', '')
        author = detail.get('user', {}).get('nickname', '')
        
        print(f"\n   ğŸ“ æ ‡é¢˜: {title[:50]}...")
        print(f"   ğŸ‘¤ ä½œè€…: {author}")
        print(f"   ğŸ“„ æ­£æ–‡é•¿åº¦: {len(desc)} å­—ç¬¦")
        
        if desc:
            print(f"   ğŸ“ƒ é¢„è§ˆ: {desc[:200]}...")
        
        explorer.close()
        
        return {
            'success': True,
            'feed_id': feed_id,
            'title': title,
            'author': author,
            'description': desc,
            'raw_data': detail
        }
        
    except Exception as e:
        print(f"   âŒ é”™è¯¯: {e}")
        return {
            'success': False,
            'feed_id': feed_id,
            'error': str(e)
        }

def test_with_cdp():
    """æµ‹è¯• CDP æ–¹å¼è·å–è¯¦æƒ…"""
    
    # è¯»å–æˆ‘ä»¬ä¹‹å‰æŠ“å–çš„æ•°æ®
    with open('/tmp/xhs_ai_crawled.json', 'r') as f:
        crawl_data = json.load(f)
    
    # ç­›é€‰é«˜è´¨é‡å†…å®¹
    high_quality = [n for n in crawl_data['notes'] if n.get('quality_score', 0) >= 8][:2]
    
    print(f"ğŸ¯ æµ‹è¯• {len(high_quality)} æ¡é«˜è´¨é‡å†…å®¹\n")
    print("=" * 70)
    
    results = []
    
    for i, note in enumerate(high_quality, 1):
        print(f"\n[{i}/{len(high_quality)}] {note['title'][:40]}...")
        result = get_feed_detail_via_cdp(note['id'], note.get('xsec_token', ''))
        results.append(result)
        time.sleep(3)
    
    # ä¿å­˜ç»“æœ
    output_path = '/tmp/xhs_cdp_results.json'
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump({
            'fetched_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'results': results
        }, f, ensure_ascii=False, indent=2)
    
    print(f"\n{'='*70}")
    print(f"âœ… æµ‹è¯•å®Œæˆ")
    success_count = sum(1 for r in results if r.get('success'))
    print(f"   æˆåŠŸ: {success_count}/{len(high_quality)}")
    print(f"   ä¿å­˜: {output_path}")
    print(f"{'='*70}")
    
    return results

if __name__ == "__main__":
    test_with_cdp()
