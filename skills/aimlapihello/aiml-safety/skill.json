{
  "name": "aimlapi-safety",
  "version": "1.0.0",
  "description": "Content moderation via AIMLAPI Guard models. Classify text as safe or unsafe instantly.",
  "main": "SKILL.md",
  "author": "OpenClaw",
  "license": "MIT",
  "scripts": {
    "test": "python scripts/check_safety.py --help"
  }
}
