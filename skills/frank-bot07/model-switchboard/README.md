# ðŸ”€ Model Switchboard

**Never crash your OpenClaw gateway again.**

Safe, redundant AI model configuration with automatic fallback chains, validation, and one-command recovery. Built for every OpenClaw user â€” from first install to production deployment.

## The Problem

Editing `openclaw.json` directly for model changes is the #1 cause of OpenClaw gateway crashes:

- Put an image model as primary LLM â†’ **gateway dead**
- Typo in model reference â†’ **gateway dead**
- Provider goes down, no fallback â†’ **gateway dead**
- No config backup â†’ **hours rebuilding from scratch**

## The Solution

Model Switchboard gives you:

- **3-deep fallback chains** â€” if Model A fails, B catches it, then C
- **Provider diversity** â€” never stack the same provider in a chain
- **Pre-flight validation** â€” blocks unsafe assignments before they touch config
- **Auto-backup** â€” snapshots config before every change (30 rolling)
- **One-command recovery** â€” `restore latest` = 2 seconds, not 5 hours
- **Per-task routing** â€” right model for the right job (conversation, coding, images, heartbeat)
- **Visual dashboard** â€” see your entire model tree at a glance
- **Setup wizard** â€” guided first-time configuration

## Quick Start

```bash
# First time? Run the setup wizard:
./scripts/switchboard.sh setup

# See current model assignments:
./scripts/switchboard.sh status

# Auto-generate 3-deep redundant config:
./scripts/switchboard.sh redundancy-apply

# Change a model (validates + backs up first):
./scripts/switchboard.sh set-primary anthropic/claude-opus-4-6

# Something broke? Instant recovery:
./scripts/switchboard.sh restore latest
```

## All Commands

**Getting Started**
- `setup` / `init` â€” First-time setup wizard with provider detection

**Model Assignment**
- `status` â€” Show current model tree + health
- `set-primary <model>` â€” Set primary LLM
- `set-image <model>` â€” Set image/vision model
- `add-fallback <model>` â€” Add LLM fallback
- `remove-fallback <model>` â€” Remove LLM fallback
- `add-image-fallback <model>` â€” Add image fallback
- `remove-image-fallback <model>` â€” Remove image fallback

**Redundancy**
- `redundancy [depth]` â€” Assess current redundancy (default: 3-deep)
- `redundancy-deploy [depth]` â€” Preview optimal redundant config
- `redundancy-apply [depth]` â€” Apply redundant config to live gateway

**Discovery & Planning**
- `discover` â€” List all available models
- `recommend` â€” Suggest optimal assignments per role
- `dry-run <action> <model>` â€” Preview changes without applying
- `validate <model> <role>` â€” Test model-role compatibility

**Backup & Restore**
- `backup` â€” Manual config backup
- `list-backups` â€” Show available backups (30 rolling)
- `restore <file|latest>` â€” Instant restore from any backup

**Import / Export**
- `export [file]` â€” Export model config as portable JSON
- `import <file>` â€” Import config (validates all models before applying)

**Diagnostics**
- `health` â€” Gateway + provider auth status
- `ui` â€” Generate Canvas dashboard data

## How Redundancy Works

Model Switchboard builds fallback chains with three rules:

1. **Minimum 3 models deep** per critical role
2. **Provider diversity** â€” never use the same provider twice in a chain
3. **Cost-appropriate** â€” expensive models for conversation, cheap ones for heartbeat

```
Primary LLM:  anthropic/claude-opus â†’ openai/gpt-5.2 â†’ google/gemini-3-pro
Image:         anthropic/claude-opus â†’ google/gemini-3-pro â†’ openai/gpt-5.1
Heartbeat:     google/gemini-flash â†’ minimax/m1 â†’ groq/llama-4
Coding:        anthropic/claude-opus â†’ openai/gpt-5.2 â†’ google/gemini-3-pro
```

If Anthropic goes down â†’ OpenAI catches it.
If OpenAI goes down â†’ Google catches it.
**Your agent never dies.**

## Task-Model Routing

Different tasks need different models. The dashboard shows two types of roles:

### Core Roles (auto-wired)
These map directly to `openclaw.json` and work immediately:
- **Primary LLM** â€” Your main conversational model
- **LLM Fallbacks** â€” Ordered backup chain for primary
- **Image Model** â€” Vision/image processing
- **Image Fallbacks** â€” Backup chain for vision

### Extended Roles (planning & reference)
These show as "(not set)" by default. They're a **visual planner** for assigning models to task types. Click any role to assign a model â€” the assignment is saved to `task-routing.json` and can be referenced when configuring cron jobs and sub-agent spawns.

- **Research** â€” Deep analysis, web search (e.g., Grok for native search)
- **Coding Pass 1/2/3** â€” Multi-pass code generation with provider diversity enforcement
- **Social Media** â€” Creative content generation
- **Web Ops** â€” Search/scrape capable models
- **Heartbeat** â€” Cheapest model for periodic polling (e.g., Haiku, Flash)

Extended roles don't auto-wire into OpenClaw's routing yet â€” they're a reference for how you want to assign models across your automation. Use them to plan your cron job model assignments and sub-agent configurations, then set the actual model param on each job accordingly.

**Example workflow:**
1. Set Research role â†’ `xai/grok-4-fast` in the dashboard
2. When creating research cron jobs, use `model: "xai/grok-4-fast"` in the job config
3. The `validate-cron-models` command checks that all your cron jobs use valid, allowed models

## Supported Providers

Works with every OpenClaw-compatible provider:

- **Anthropic** â€” Claude Opus, Sonnet, Haiku
- **OpenAI** â€” GPT-5.x family, Codex
- **Google** â€” Gemini 3 Pro, 2.5 Flash, Vertex AI
- **OpenCode Zen** â€” Multi-model proxy
- **Z.AI** â€” GLM family
- **xAI** â€” Grok (search-enabled)
- **OpenRouter** â€” 300+ models from all providers
- **Groq** â€” Ultra-fast inference
- **Cerebras** â€” Fast inference
- **MiniMax** â€” Cost-effective LLM
- **Vercel AI Gateway** â€” Enterprise proxy

## Safety Guarantees

1. **Fail-closed** â€” if validation can't run, changes are blocked (not allowed through)
2. **Type enforcement** â€” image-gen models (DALL-E) can never be set as primary LLM
3. **Atomic writes** â€” config written to temp file, validated, then renamed (no corruption)
4. **Operation-specific rollback** â€” each change tracks its own backup (not just "latest")
5. **XSS-safe dashboard** â€” all data rendered via textContent/createElement, never raw innerHTML
6. **Opus-audited** â€” full security audit by Claude Opus, all findings fixed

## Requirements

- **OpenClaw** â€” any recent version
- **Python 3.8+** â€” pre-installed on macOS and most Linux
- **Bash 3.2+** â€” pre-installed on macOS, Linux, WSL
- **No external dependencies** â€” no npm, no pip, no network required

## File Structure

```
model-switchboard/
â”œâ”€â”€ SKILL.md                 â€” Agent instructions (read by OpenClaw agents)
â”œâ”€â”€ README.md                â€” This file
â”œâ”€â”€ ARCHITECTURE.md          â€” Vision and design docs
â”œâ”€â”€ model-registry.json      â€” Known model capabilities (22 models, 14 providers)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ switchboard.sh       â€” Main CLI (21 commands)
â”‚   â”œâ”€â”€ validate.py          â€” Fail-closed validation engine
â”‚   â”œâ”€â”€ redundancy.py        â€” Auto-generates optimal fallback chains
â”‚   â””â”€â”€ setup.sh             â€” First-time setup wizard
â””â”€â”€ ui/
    â””â”€â”€ index.html           â€” Canvas dashboard (XSS-safe)
```

## For OpenClaw Agents

If you're an AI agent reading this: **NEVER edit `openclaw.json` model fields directly.** Always use this skill's commands. Read `SKILL.md` for complete operating instructions.

## Contributing

- **Add models:** Edit `model-registry.json` with new model capabilities
- **Add providers:** Add to the providers section with auth env vars
- **Report bugs:** Open an issue with your OS, Python version, and error output
- **Share configs:** Use `export` to share your optimal model setup

## License

MIT â€” Free and open source for every OpenClaw user.

---

*Built with love for the OpenClaw community. No agent should ever go dark because of a config mistake.*
