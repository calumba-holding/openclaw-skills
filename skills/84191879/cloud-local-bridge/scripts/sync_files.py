#!/usr/bin/env python3
"""
æ–‡ä»¶åŒæ­¥è„šæœ¬
åœ¨äº‘ç«¯å’Œæœ¬åœ°ä¹‹é—´åŒæ­¥æ–‡ä»¶/ç›®å½•
"""

import os
import json
import argparse
from pathlib import Path
import hashlib
import pickle
from datetime import datetime

try:
    import requests
except ImportError:
    print("è¯·å®‰è£… requests: pip install requests")
    exit(1)


class FileSync:
    def __init__(self, server_url, token, sync_file='.sync_cache.pkl'):
        self.server_url = server_url.rstrip('/')
        self.token = token
        self.sync_cache_file = sync_file
        self.cache = self.load_cache()
    
    def load_cache(self):
        """åŠ è½½åŒæ­¥ç¼“å­˜"""
        if os.path.exists(self.sync_cache_file):
            with open(self.sync_cache_file, 'rb') as f:
                return pickle.load(f)
        return {}
    
    def save_cache(self):
        """ä¿å­˜åŒæ­¥ç¼“å­˜"""
        with open(self.sync_cache_file, 'wb') as f:
            pickle.dump(self.cache, f)
    
    def get_file_hash(self, filepath):
        """è®¡ç®—æ–‡ä»¶å“ˆå¸Œ"""
        if not os.path.isfile(filepath):
            return None
        hasher = hashlib.md5()
        with open(filepath, 'rb') as f:
            hasher.update(f.read())
        return hasher.hexdigest()
    
    def sync_to_remote(self, local_dir, remote_base):
        """åŒæ­¥æœ¬åœ°ç›®å½•åˆ°è¿œç¨‹"""
        import base64
        
        local_path = Path(local_dir)
        if not local_path.exists():
            print(f"âŒ æœ¬åœ°ç›®å½•ä¸å­˜åœ¨: {local_dir}")
            return
        
        changes = []
        
        for root, dirs, files in os.walk(local_path):
            rel_dir = os.path.relpath(root, local_path)
            
            for file in files:
                local_file = os.path.join(root, file)
                remote_file = os.path.join(remote_base, rel_dir, file) if rel_dir != '.' else os.path.join(remote_base, file)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰å˜åŒ–
                file_hash = self.get_file_hash(local_file)
                cache_key = remote_file
                
                if self.cache.get(cache_key) != file_hash:
                    changes.append((local_file, remote_file))
        
        if not changes:
            print("âœ… æ²¡æœ‰éœ€è¦åŒæ­¥çš„æ–‡ä»¶")
            return
        
        print(f"ğŸ“¤ å‡†å¤‡åŒæ­¥ {len(changes)} ä¸ªæ–‡ä»¶...")
        
        for local_file, remote_file in changes:
            try:
                # è¯»å–å¹¶ç¼–ç æ–‡ä»¶
                with open(local_file, 'rb') as f:
                    content = base64.b64encode(f.read()).decode('utf-8')
                
                # ä¸Šä¼ 
                response = requests.post(
                    f"{self.server_url}/file",
                    json={
                        "action": "upload",
                        "path": remote_file,
                        "base64_content": content
                    },
                    headers={"Authorization": f"Bearer {self.token}"}
                )
                
                if response.status_code == 200:
                    # æ›´æ–°ç¼“å­˜
                    self.cache[remote_file] = self.get_file_hash(local_file)
                    print(f"  âœ… {remote_file}")
                else:
                    print(f"  âŒ {remote_file}: {response.text}")
                    
            except Exception as e:
                print(f"  âŒ {remote_file}: {e}")
        
        self.save_cache()
        print(f"âœ… å®Œæˆ! åŒæ­¥äº† {len(changes)} ä¸ªæ–‡ä»¶")
    
    def sync_from_remote(self, remote_dir, local_base):
        """ä»è¿œç¨‹åŒæ­¥åˆ°æœ¬åœ°"""
        response = requests.post(
            f"{self.server_url}/file",
            json={
                "action": "list",
                "path": remote_dir
            },
            headers={"Authorization": f"Bearer {self.token}"}
        )
        
        if response.status_code != 200:
            print(f"âŒ è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {response.text}")
            return
        
        files = response.json().get('files', [])
        
        for remote_file in files:
            local_file = os.path.join(local_base, os.path.relpath(remote_file, remote_dir))
            
            # ä¸‹è½½æ–‡ä»¶
            response = requests.post(
                f"{self.server_url}/file",
                json={
                    "action": "download",
                    "path": remote_file
                },
                headers={"Authorization": f"Bearer {self.token}"}
            )
            
            if response.status_code == 200:
                result = response.json()
                if 'base64_content' in result:
                    import base64
                    os.makedirs(os.path.dirname(local_file), exist_ok=True)
                    content = base64.b64decode(result['base64_content'])
                    with open(local_file, 'wb') as f:
                        f.write(content)
                    print(f"  âœ… {local_file}")


def main():
    parser = argparse.ArgumentParser(description='æ–‡ä»¶åŒæ­¥å·¥å…·')
    parser.add_argument('--server', required=True, help='Bridge æœåŠ¡å™¨åœ°å€')
    parser.add_argument('--token', required=True, help='è®¤è¯ token')
    parser.add_argument('--local', required=True, help='æœ¬åœ°ç›®å½•')
    parser.add_argument('--remote', required=True, help='è¿œç¨‹è·¯å¾„')
    parser.add_argument('--direction', choices=['upload', 'download', 'sync'], 
                        default='sync', help='åŒæ­¥æ–¹å‘')
    
    args = parser.parse_args()
    
    sync = FileSync(args.server, args.token)
    
    if args.direction in ['upload', 'sync']:
        print(f"ğŸ“¤ åŒæ­¥åˆ°è¿œç¨‹: {args.remote}")
        sync.sync_to_remote(args.local, args.remote)
    
    if args.direction in ['download', 'sync']:
        print(f"ğŸ“¥ ä»è¿œç¨‹åŒæ­¥: {args.remote}")
        sync.sync_from_remote(args.remote, args.local)


if __name__ == '__main__':
    main()
