# AIOps Agent - AIé©±åŠ¨çš„æ™ºèƒ½è¿ç»´ç³»ç»Ÿ

> å°†ä¼ ç»Ÿè¢«åŠ¨å‘Šè­¦å‡çº§ä¸ºä¸»åŠ¨é¢„æµ‹ã€æ™ºèƒ½è¯Šæ–­å’Œè‡ªåŠ¨åŒ–æ²»ç†çš„æ–°ä¸€ä»£AIOpså¹³å°

---

## ğŸ“‹ æ¦‚è¿°

**AIOps Agent**æ˜¯ä¸€ä¸ªåŸºäºAIçš„æ™ºèƒ½è¿ç»´ä»£ç†ç³»ç»Ÿï¼Œé€šè¿‡å¤šç»´åº¦æ•°æ®é‡‡é›†ã€æ™ºèƒ½åˆ†æå’Œè‡ªåŠ¨åŒ–æ‰§è¡Œï¼Œå®ç°ï¼š

- âš¡ **ä¸»åŠ¨é¢„è­¦** - æå‰1-3å°æ—¶å‘ç°æ½œåœ¨é£é™©
- ğŸ” **æ™ºèƒ½è¯Šæ–­** - è‡ªåŠ¨åŒ–æ ¹å› åˆ†æï¼Œå‡å°‘70%+æ’æŸ¥æ—¶é—´
- ğŸŒ™ **é£é™©å‰ç½®** - å‡å°‘80%+å‡Œæ™¨å‘Šè­¦
- ğŸ¤– **è‡ªåŠ¨åŒ–æ²»ç†** - æ”¯æŒè‡ªåŠ¨ä¿®å¤å’ŒåŠè‡ªåŠ¨åŒ–è¿ç»´

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

```bash
# å¿…éœ€
- Python 3.11+
- Docker & Docker Compose
- Kubernetes é›†ç¾¤ï¼ˆå¯é€‰ï¼‰

# ä¾èµ–æœåŠ¡
- Prometheusï¼ˆæŒ‡æ ‡ï¼‰
- Lokiï¼ˆæ—¥å¿—ï¼‰
- PostgreSQLï¼ˆå­˜å‚¨ï¼‰
- Redisï¼ˆç¼“å­˜ï¼‰
```

### 2. æœ¬åœ°å¯åŠ¨

```bash
# å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd sre-agent

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env å¡«å…¥å¿…è¦é…ç½®

# å¯åŠ¨æ‰€æœ‰æœåŠ¡ï¼ˆDocker Composeï¼‰
make up

# æˆ–æ‰‹åŠ¨å¯åŠ¨
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f sre-agent
```

### 3. è®¿é—®æœåŠ¡

```
API:      http://localhost:8000
æ–‡æ¡£:     http://localhost:8000/docs
å¥åº·æ£€æŸ¥: http://localhost:8000/health
```

---

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½

### 1. å¤šç»´åº¦æ•°æ®é‡‡é›†

```yaml
# config/config.yaml
data_sources:
  prometheus:
    url: "http://prometheus:9090"
    metrics:
      - cpu_usage
      - memory_usage
      - disk_io
      - network_traffic
  
  loki:
    url: "http://loki:3100"
    query: '{namespace="production"}'
  
  kubernetes:
    enabled: true
    events: true
```

### 2. AIé©±åŠ¨åˆ†æ

**å¼‚å¸¸æ£€æµ‹:**
```python
# ä½¿ç”¨å¤šç®—æ³•æ£€æµ‹å¼‚å¸¸
from src.cognition.anomaly_detector import AnomalyDetector

detector = AnomalyDetector()
anomalies = detector.detect(
    metric_name="cpu_usage",
    values=cpu_data,
    sensitivity=0.95
)
```

**è¶‹åŠ¿é¢„æµ‹:**
```python
# é¢„æµ‹æœªæ¥1-6å°æ—¶èµ°åŠ¿
from src.cognition.predictor import Predictor

predictor = Predictor()
forecast = predictor.predict(
    metric_name="memory_usage",
    horizon_hours=3
)
```

**æ ¹å› åˆ†æ:**
```python
# LLMé©±åŠ¨çš„æ™ºèƒ½æ ¹å› åˆ†æ
from src.cognition.rca_engine import RCAEngine

rca = RCAEngine()
analysis = rca.analyze(
    anomaly=anomaly_event,
    context={
        'metrics': related_metrics,
        'logs': error_logs,
        'events': k8s_events
    }
)
```

### 3. æ™ºèƒ½å†³ç­–

```python
# é£é™©è¯„ä¼°
from src.decision.risk_assessment import RiskAssessor

assessor = RiskAssessor()
risk = assessor.evaluate(
    anomaly=anomaly,
    impact_analysis=impact,
    historical_cases=similar_cases
)

# é£é™©ç­‰çº§: CRITICAL / HIGH / MEDIUM / LOW
```

### 4. è‡ªåŠ¨åŒ–æ‰§è¡Œ

```python
# è‡ªåŠ¨ä¿®å¤
from src.action.executor import ActionExecutor

executor = ActionExecutor()
result = executor.execute(
    action_type="restart_pod",
    target="production/nginx-deployment",
    approval_required=True
)
```

---

## ğŸ“Š æ¶æ„è®¾è®¡

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   SRE Agent ç³»ç»Ÿæ¶æ„                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Perception  â”‚â”€â”€â–¶â”‚  Cognition   â”‚â”€â”€â–¶â”‚  Decision   â”‚ â”‚
â”‚  â”‚  (æ„ŸçŸ¥å±‚)     â”‚   â”‚  (è®¤çŸ¥å±‚)     â”‚   â”‚  (å†³ç­–å±‚)    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚                   â”‚       â”‚
â”‚         â–¼                   â–¼                   â–¼       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              Action (è¡ŒåŠ¨å±‚)                     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

æ•°æ®æº: Prometheus, Loki, Kubernetes, Jaeger
AIå¼•æ“: Baseline, Anomaly Detection, Prediction, RCA
æ‰§è¡Œå™¨: Kubernetes API, Shell, Playbooks
```

### æ ¸å¿ƒç»„ä»¶

1. **Perception (æ„ŸçŸ¥å±‚)**
   - æŒ‡æ ‡é‡‡é›†å™¨
   - æ—¥å¿—èšåˆå™¨
   - äº‹ä»¶ç›‘å¬å™¨

2. **Cognition (è®¤çŸ¥å±‚)**
   - åŸºçº¿å¼•æ“
   - å¼‚å¸¸æ£€æµ‹å™¨
   - è¶‹åŠ¿é¢„æµ‹å™¨
   - æ ¹å› åˆ†æå¼•æ“

3. **Decision (å†³ç­–å±‚)**
   - é£é™©è¯„ä¼°å™¨
   - è¡ŒåŠ¨è§„åˆ’å™¨
   - çŸ¥è¯†åº“

4. **Action (è¡ŒåŠ¨å±‚)**
   - æ‰§è¡Œå¼•æ“
   - å®¡æ‰¹æµç¨‹
   - åé¦ˆå¾ªç¯

---

## ğŸ› ï¸ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: CPUä½¿ç”¨ç‡å¼‚å¸¸é¢„è­¦

```python
# 1. ç³»ç»Ÿæ£€æµ‹åˆ°CPUä½¿ç”¨ç‡å¼‚å¸¸ä¸Šå‡
anomaly = {
    'metric': 'cpu_usage',
    'current_value': 85.2,
    'baseline': 45.3,
    'deviation': 3.5  # æ ‡å‡†å·®
}

# 2. é¢„æµ‹è¶‹åŠ¿
forecast = predictor.predict('cpu_usage', hours=2)
# é¢„æµ‹ç»“æœ: 2å°æ—¶åå°†è¾¾åˆ°95%

# 3. æ ¹å› åˆ†æ
root_cause = rca.analyze(anomaly)
# å¯èƒ½åŸå› : æŸä¸ªPodå†…å­˜æ³„æ¼å¯¼è‡´é¢‘ç¹GC

# 4. ç”Ÿæˆè¡ŒåŠ¨æ–¹æ¡ˆ
actions = planner.generate_actions(root_cause)
# å»ºè®®: é‡å¯é—®é¢˜Pod

# 5. å‘é€å‘Šè­¦ï¼ˆæå‰é¢„è­¦ï¼‰
alert.send(
    level='WARNING',
    message='é¢„æµ‹2å°æ—¶åCPUå°†è¾¾åˆ°95%ï¼Œå»ºè®®ç«‹å³å¤„ç†',
    actions=actions
)
```

### åœºæ™¯2: å†…å­˜æ³„æ¼è‡ªåŠ¨è¯Šæ–­

```python
# 1. æ£€æµ‹åˆ°å†…å­˜æŒç»­ä¸Šå‡
anomaly = detector.detect_trend(
    metric='memory_usage',
    pattern='monotonic_increase'
)

# 2. å…³è”åˆ†æ
context = correlator.analyze({
    'metrics': ['heap_usage', 'gc_time'],
    'logs': loki.query('{app="backend"} |= "OutOfMemory"'),
    'events': k8s.get_pod_events('backend-pod')
})

# 3. LLMåˆ†æ
diagnosis = llm.analyze(f"""
æ ¹æ®ä»¥ä¸‹ä¿¡æ¯è¯Šæ–­å†…å­˜æ³„æ¼:
- å†…å­˜ä½¿ç”¨ç‡: {anomaly}
- å †å†…å­˜: {context['heap_usage']}
- GCæ—¶é—´: {context['gc_time']}
- é”™è¯¯æ—¥å¿—: {context['logs']}
""")

# 4. è‡ªåŠ¨æ‰§è¡Œä¿®å¤
if diagnosis.confidence > 0.8:
    executor.restart_pod('backend-pod')
```

### åœºæ™¯3: ç£ç›˜ç©ºé—´é¢„æµ‹æ€§æ‰©å®¹

```python
# 1. é¢„æµ‹ç£ç›˜ä½¿ç”¨
forecast = predictor.predict('disk_usage', days=7)

# 2. é£é™©è¯„ä¼°
if forecast.max_value > 80:
    risk = assessor.evaluate(
        metric='disk_usage',
        forecast=forecast,
        impact='HIGH'  # ç£ç›˜æ»¡ä¼šå¯¼è‡´æœåŠ¡ä¸å¯ç”¨
    )
    
    # 3. ç”Ÿæˆæ‰©å®¹æ–¹æ¡ˆ
    plan = planner.create_scaling_plan(
        resource='disk',
        current_size='100Gi',
        target_size='200Gi',
        urgency=risk.level
    )
    
    # 4. æäº¤å®¡æ‰¹ï¼ˆå…³é”®æ“ä½œï¼‰
    approval = workflow.submit_for_approval(plan)
```

---

## ğŸ“š é…ç½®è¯´æ˜

### åŸºç¡€é…ç½® (config/config.yaml)

```yaml
# AIå¼•æ“é…ç½®
ai:
  llm:
    provider: "openai"  # openai / azure / local
    model: "gpt-4"
    temperature: 0.3
  
  anomaly_detection:
    algorithms:
      - statistical  # ç»Ÿè®¡æ–¹æ³•
      - isolation_forest  # å­¤ç«‹æ£®æ—
      - prophet  # Facebook Prophet
    sensitivity: 0.95
  
  prediction:
    model: "prophet"  # prophet / lstm / arima
    horizon_hours: 6

# å‘Šè­¦é…ç½®
alerting:
  channels:
    - type: "slack"
      webhook_url: "${SLACK_WEBHOOK}"
    - type: "email"
      smtp_server: "smtp.gmail.com"
      recipients: ["oncall@example.com"]
  
  rules:
    - name: "é«˜é£é™©ç«‹å³é€šçŸ¥"
      condition: "risk_level == 'CRITICAL'"
      channels: ["slack", "email", "phone"]
    
    - name: "ä¸­é£é™©ç™½å¤©é€šçŸ¥"
      condition: "risk_level == 'HIGH' and 8 <= hour <= 20"
      channels: ["slack"]

# è‡ªåŠ¨åŒ–é…ç½®
automation:
  approval_required:
    - "scale_deployment"
    - "delete_resource"
    - "rollback_deployment"
  
  auto_approve:
    - "restart_pod"
    - "clear_cache"
```

### PrometheusæŸ¥è¯¢ (config/promql_queries.yaml)

```yaml
cpu_usage:
  query: "rate(container_cpu_usage_seconds_total[5m])"
  threshold: 0.8

memory_usage:
  query: "container_memory_usage_bytes / container_spec_memory_limit_bytes"
  threshold: 0.85

disk_io:
  query: "rate(container_fs_reads_bytes_total[5m]) + rate(container_fs_writes_bytes_total[5m])"
  threshold: 100000000  # 100MB/s
```

---

## ğŸ”§ å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„å¼‚å¸¸æ£€æµ‹ç®—æ³•

```python
# src/cognition/anomaly_detector.py

from src.cognition.base import BaseDetector

class MyCustomDetector(BaseDetector):
    """è‡ªå®šä¹‰å¼‚å¸¸æ£€æµ‹å™¨"""
    
    def detect(self, data, **kwargs):
        # å®ç°æ£€æµ‹é€»è¾‘
        threshold = kwargs.get('threshold', 0.95)
        
        # ä½ çš„ç®—æ³•
        anomalies = []
        for point in data:
            if self._is_anomaly(point, threshold):
                anomalies.append(point)
        
        return anomalies
    
    def _is_anomaly(self, point, threshold):
        # åˆ¤æ–­é€»è¾‘
        pass

# æ³¨å†Œåˆ°ç³»ç»Ÿ
from src.cognition import register_detector
register_detector('my_custom', MyCustomDetector)
```

### æ·»åŠ æ–°çš„æ‰§è¡Œå™¨

```python
# src/action/executors/my_executor.py

from src.action.base import BaseExecutor

class MyExecutor(BaseExecutor):
    """è‡ªå®šä¹‰æ‰§è¡Œå™¨"""
    
    def execute(self, action, context):
        # å®ç°æ‰§è¡Œé€»è¾‘
        target = action['target']
        params = action['params']
        
        # æ‰§è¡Œæ“ä½œ
        result = self._do_action(target, params)
        
        return {
            'success': True,
            'result': result,
            'timestamp': datetime.now()
        }
```

---

## ğŸ“ˆ ç›‘æ§ä¸å‘Šè­¦

### Grafana ä»ªè¡¨ç›˜

ç³»ç»Ÿæä¾›é¢„é…ç½®çš„Grafanaä»ªè¡¨ç›˜ï¼š

```
http://localhost:3000

ä»ªè¡¨ç›˜:
- AIOps Overview: ç³»ç»Ÿæ€»è§ˆ
- Anomaly Detection: å¼‚å¸¸æ£€æµ‹
- Risk Assessment: é£é™©è¯„ä¼°
- Action History: æ‰§è¡Œå†å²
```

### å‘Šè­¦é€šé“

æ”¯æŒå¤šç§å‘Šè­¦æ–¹å¼ï¼š

| é€šé“ | ç”¨é€” | é…ç½® |
|------|------|------|
| Slack | æ—¥å¸¸é€šçŸ¥ | SLACK_WEBHOOK |
| Email | é‡è¦å‘Šè­¦ | SMTPé…ç½® |
| ä¼ä¸šå¾®ä¿¡ | ä¸­å›½å›¢é˜Ÿ | WECHAT_WEBHOOK |
| PagerDuty | å€¼ç­è½®æ¢ | PAGERDUTY_KEY |

---

## ğŸ› æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

**Q: å¼‚å¸¸æ£€æµ‹è¯¯æŠ¥ç‡é«˜ï¼Ÿ**

A: è°ƒæ•´æ•æ„Ÿåº¦å‚æ•°ï¼š
```yaml
ai:
  anomaly_detection:
    sensitivity: 0.9  # é™ä½åˆ°0.9ï¼ˆé»˜è®¤0.95ï¼‰
```

**Q: LLMå“åº”æ…¢ï¼Ÿ**

A: ä½¿ç”¨æœ¬åœ°æ¨¡å‹æˆ–å¢åŠ è¶…æ—¶ï¼š
```yaml
ai:
  llm:
    timeout: 30  # å¢åŠ åˆ°30ç§’
    cache_enabled: true  # å¯ç”¨ç¼“å­˜
```

**Q: Kubernetesæƒé™ä¸è¶³ï¼Ÿ**

A: æ£€æŸ¥RBACé…ç½®ï¼š
```bash
kubectl apply -f k8s/rbac.yaml
```

---

## ğŸ§ª æµ‹è¯•

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
make test

# å•ç‹¬æµ‹è¯•æ¨¡å—
pytest tests/test_anomaly_detector.py -v

# è¦†ç›–ç‡æŠ¥å‘Š
make coverage
```

---

## ğŸ“¦ éƒ¨ç½²

### Dockeréƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
make build

# æ¨é€åˆ°ä»“åº“
docker push your-registry/sre-agent:v1.0

# è¿è¡Œ
docker run -d \
  -p 8000:8000 \
  -e PROMETHEUS_URL=http://prometheus:9090 \
  your-registry/sre-agent:v1.0
```

### Kuberneteséƒ¨ç½²

```bash
# åº”ç”¨é…ç½®
kubectl apply -f k8s/namespace.yaml
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/deployment.yaml
kubectl apply -f k8s/service.yaml

# æ£€æŸ¥çŠ¶æ€
kubectl get pods -n aiops
```

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æäº¤Issueæˆ–åŠŸèƒ½å»ºè®®ï¼

---

## ğŸ“„ è®¸å¯è¯

MIT License

---

## ğŸ‘¥ ä½œè€…

**James Mei**
- ğŸ“§ Email: meijinmeng@126.com
- ğŸ“ Blog: https://www.cnblogs.com/Jame-mei
- ğŸ™ GitHub: [Your GitHub]

---

## ğŸ”— ç›¸å…³èµ„æº

- [README.md](./README.md) - å®Œæ•´æ–‡æ¡£
- [QUICKSTART.md](./docs/QUICKSTART.md) - å¿«é€Ÿå¼€å§‹
- [CONFIGURATION.md](./docs/CONFIGURATION.md) - é…ç½®æŒ‡å—
- [IMPLEMENTATION.md](./docs/IMPLEMENTATION.md) - å®ç°ç»†èŠ‚

---

_è®©AIä¸ºè¿ç»´èµ‹èƒ½ï¼ğŸš€_
