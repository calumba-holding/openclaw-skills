---
name: agent-optimizer
description: V6.1 Agent æ€§èƒ½ä¼˜åŒ–å™¨ - åŸºäºŽè½¨è¿¹åˆ†æžå’Œå¥–åŠ±åé¦ˆçš„è½»é‡çº§ä¼˜åŒ–æ¡†æž¶
homepage: https://github.com/openclaw/openclaw
metadata: {"openclaw":{"emoji":"âš¡","requires":{"bins":["python3"],"env":[]},"primaryEnv":""}}
---

# Agent Optimizer âš¡

**V6.1 è”é‚¦æ™ºèƒ½ä¸“ç”¨ - è½»é‡çº§ Agent æ€§èƒ½ä¼˜åŒ–æ¡†æž¶**

æ— éœ€å¤–éƒ¨ä¾èµ–ï¼ŒåŸºäºŽ OpenClaw åŽŸç”Ÿèƒ½åŠ›å®žçŽ° Agent æ€§èƒ½æŒç»­ä¼˜åŒ–ã€‚

## ðŸ”¥ æ ¸å¿ƒåŠŸèƒ½

### 1. è½¨è¿¹è®°å½•
- è‡ªåŠ¨è®°å½• Agent æ‰§è¡Œè½¨è¿¹
- ä¿å­˜è¾“å…¥ã€è¾“å‡ºã€å·¥å…·è°ƒç”¨ã€è€—æ—¶
- ç»“æž„åŒ–å­˜å‚¨ä¾¿äºŽåˆ†æž

### 2. å¥–åŠ±åé¦ˆ
- æ”¯æŒå¤šç§å¥–åŠ±ä¿¡å·ï¼ˆç”¨æˆ·è¯„åˆ†ã€ä»»åŠ¡å®Œæˆåº¦ã€ROI ç­‰ï¼‰
- ç´¯ç§¯å¥–åŠ±ç»Ÿè®¡
- å¥–åŠ±è¶‹åŠ¿åˆ†æž

### 3. æç¤ºè¯ä¼˜åŒ–
- åŸºäºŽå¥–åŠ±åé¦ˆè‡ªåŠ¨ä¼˜åŒ–æç¤ºè¯
- A/B æµ‹è¯•ä¸åŒæç¤ºè¯ç‰ˆæœ¬
- ä¿ç•™åŽ†å²ç‰ˆæœ¬å¯å›žæ»š

### 4. æ€§èƒ½åˆ†æž
- æ‰§è¡Œè€—æ—¶åˆ†æž
- æˆåŠŸçŽ‡ç»Ÿè®¡
- ROI è®¡ç®—ä¸Žè¿½è¸ª

## ðŸ“¦ å®‰è£…

æ— éœ€å®‰è£…ï¼Œå·²é›†æˆåˆ° OpenClaw V6.1 å·¥ä½œåŒºã€‚

## ðŸš€ å¿«é€Ÿå¼€å§‹

### 1. åˆå§‹åŒ–ä¼˜åŒ–å™¨

```python
# åœ¨å­ Agent å·¥ä½œåŒºåˆ›å»º optimizer ç›®å½•
mkdir -p /workspace/subagents/{agent_id}/optimizer

# åˆ›å»ºé…ç½®æ–‡ä»¶
cat > /workspace/subagents/{agent_id}/optimizer/config.json << 'EOF'
{
  "agent_id": "techbot",
  "optimization_target": "tutorial_quality",
  "metrics": ["user_rating", "completion_rate", "roi"],
  "ab_test": true
}
EOF
```

### 2. è®°å½•æ‰§è¡Œè½¨è¿¹

```python
import json
from datetime import datetime

def record_trajectory(agent_id, task, output, metrics):
    """è®°å½• Agent æ‰§è¡Œè½¨è¿¹"""
    timestamp = datetime.now().isoformat()
    
    trajectory = {
        "agent_id": agent_id,
        "timestamp": timestamp,
        "task": task,
        "output": output,
        "metrics": metrics,
        "prompt_version": get_current_prompt_version()
    }
    
    # ä¿å­˜åˆ°è½¨è¿¹æ–‡ä»¶
    with open(f'/workspace/subagents/{agent_id}/optimizer/trajectories.jsonl', 'a') as f:
        f.write(json.dumps(trajectory) + '\n')
    
    return trajectory
```

### 3. å‘å°„å¥–åŠ±ä¿¡å·

```python
def emit_reward(agent_id, trajectory_id, reward_value, reward_type="user_rating"):
    """å‘å°„å¥–åŠ±ä¿¡å·"""
    timestamp = datetime.now().isoformat()
    
    reward = {
        "agent_id": agent_id,
        "trajectory_id": trajectory_id,
        "timestamp": timestamp,
        "reward_value": reward_value,
        "reward_type": reward_type
    }
    
    # ä¿å­˜åˆ°å¥–åŠ±æ–‡ä»¶
    with open(f'/workspace/subagents/{agent_id}/optimizer/rewards.jsonl', 'a') as f:
        f.write(json.dumps(reward) + '\n')
    
    return reward
```

### 4. åˆ†æžæ€§èƒ½å¹¶ä¼˜åŒ–

```python
def analyze_and_optimize(agent_id):
    """åˆ†æžæ€§èƒ½å¹¶ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
    import json
    
    # åŠ è½½è½¨è¿¹æ•°æ®
    trajectories = []
    with open(f'/workspace/subagents/{agent_id}/optimizer/trajectories.jsonl', 'r') as f:
        for line in f:
            trajectories.append(json.loads(line))
    
    # åŠ è½½å¥–åŠ±æ•°æ®
    rewards = []
    with open(f'/workspace/subagents/{agent_id}/optimizer/rewards.jsonl', 'r') as f:
        for line in f:
            rewards.append(json.loads(line))
    
    # è®¡ç®—å¹³å‡å¥–åŠ±
    avg_reward = sum(r['reward_value'] for r in rewards) / len(rewards) if rewards else 0
    
    # åˆ†æžé«˜å¥–åŠ±å’Œä½Žå¥–åŠ±è½¨è¿¹
    high_reward_trajectories = [t for t in trajectories if get_reward(t['task'], rewards) > avg_reward]
    low_reward_trajectories = [t for t in trajectories if get_reward(t['task'], rewards) < avg_reward]
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    optimization_report = {
        "agent_id": agent_id,
        "total_trajectories": len(trajectories),
        "total_rewards": len(rewards),
        "average_reward": avg_reward,
        "high_reward_patterns": analyze_patterns(high_reward_trajectories),
        "low_reward_patterns": analyze_patterns(low_reward_trajectories),
        "suggestions": generate_suggestions(high_reward_trajectories, low_reward_trajectories)
    }
    
    # ä¿å­˜æŠ¥å‘Š
    with open(f'/workspace/subagents/{agent_id}/optimizer/optimization_report.json', 'w') as f:
        json.dump(optimization_report, f, indent=2)
    
    return optimization_report
```

## ðŸ“Š ä½¿ç”¨åœºæ™¯

### TechBot - æ•™ç¨‹è´¨é‡ä¼˜åŒ–
```python
# è®°å½•æ•™ç¨‹ç”Ÿæˆè½¨è¿¹
trajectory = record_trajectory(
    agent_id="techbot",
    task="ç¼–å†™ AI Agent æ•™ç¨‹",
    output=tutorial_content,
    metrics={
        "word_count": len(tutorial_content),
        "code_blocks": count_code_blocks(tutorial_content),
        "execution_time": execution_time
    }
)

# ç”¨æˆ·è¯„åˆ†åŽå‘å°„å¥–åŠ±
emit_reward(
    agent_id="techbot",
    trajectory_id=trajectory['task'],
    reward_value=user_rating,  # 1-5 åˆ†
    reward_type="user_rating"
)

# å®šæœŸåˆ†æžä¼˜åŒ–
report = analyze_and_optimize("techbot")
print(f"å¹³å‡è¯„åˆ†ï¼š{report['average_reward']:.2f}")
print(f"ä¼˜åŒ–å»ºè®®ï¼š{report['suggestions']}")
```

### FinanceBot - ROI é¢„æµ‹ä¼˜åŒ–
```python
# è®°å½• ROI é¢„æµ‹è½¨è¿¹
trajectory = record_trajectory(
    agent_id="financebot",
    task="é¢„æµ‹ä»»åŠ¡ ROI",
    output={"predicted_roi": 2.5, "confidence": 0.85},
    metrics={
        "prediction_accuracy": 0.0,  # å¾…å®žé™…ç»“æžœå‡ºæ¥åŽæ›´æ–°
        "confidence_score": 0.85
    }
)

# å®žé™…ç»“æžœå‡ºæ¥åŽå‘å°„å¥–åŠ±
actual_roi = 2.3
prediction_error = abs(2.5 - actual_roi)
reward = 1.0 / (1.0 + prediction_error)  # è¯¯å·®è¶Šå°å¥–åŠ±è¶Šé«˜

emit_reward(
    agent_id="financebot",
    trajectory_id=trajectory['task'],
    reward_value=reward,
    reward_type="prediction_accuracy"
)
```

### AutoBot - æŠ“å–æˆåŠŸçŽ‡ä¼˜åŒ–
```python
# è®°å½•æ•°æ®æŠ“å–è½¨è¿¹
trajectory = record_trajectory(
    agent_id="autobot",
    task="æŠ“å–ç½‘ç«™æ•°æ®",
    output={"status": "success", "data_points": 150},
    metrics={
        "success": True,
        "data_points": 150,
        "retry_count": 0
    }
)

# æ ¹æ®æˆåŠŸçŽ‡å‘å°„å¥–åŠ±
reward = 1.0 if trajectory['output']['status'] == 'success' else 0.0
emit_reward(
    agent_id="autobot",
    trajectory_id=trajectory['task'],
    reward_value=reward,
    reward_type="success_rate"
)
```

## ðŸ“ˆ æ€§èƒ½åˆ†æžå·¥å…·

### 1. å¥–åŠ±è¶‹åŠ¿åˆ†æž
```bash
# ç”Ÿæˆå¥–åŠ±è¶‹åŠ¿å›¾æ•°æ®
python3 /workspace/skills/agent-optimizer/scripts/analyze_trends.py --agent techbot
```

### 2. A/B æµ‹è¯•
```python
# æµ‹è¯•ä¸¤ä¸ªæç¤ºè¯ç‰ˆæœ¬
def ab_test_prompt(agent_id, task, version_a, version_b):
    # éšæœºé€‰æ‹©ç‰ˆæœ¬
    import random
    version = random.choice(['a', 'b'])
    
    if version == 'a':
        output = execute_with_prompt(task, version_a)
    else:
        output = execute_with_prompt(task, version_b)
    
    # è®°å½•å¹¶æ¯”è¾ƒç»“æžœ
    return output, version
```

### 3. æç¤ºè¯ç‰ˆæœ¬ç®¡ç†
```python
# ä¿å­˜æç¤ºè¯ç‰ˆæœ¬
def save_prompt_version(agent_id, version, prompt_template):
    with open(f'/workspace/subagents/{agent_id}/optimizer/prompts/v{version}.txt', 'w') as f:
        f.write(prompt_template)

# åŠ è½½æç¤ºè¯ç‰ˆæœ¬
def load_prompt_version(agent_id, version):
    with open(f'/workspace/subagents/{agent_id}/optimizer/prompts/v{version}.txt', 'r') as f:
        return f.read()
```

## ðŸ”§ é…ç½®æ–‡ä»¶ç¤ºä¾‹

### optimizer/config.json
```json
{
  "agent_id": "techbot",
  "optimization_target": "tutorial_quality",
  "metrics": ["user_rating", "completion_rate", "roi"],
  "ab_test": true,
  "prompt_versions": ["v1.0", "v1.1", "v2.0"],
  "current_version": "v2.0",
  "optimization_interval": 100
}
```

### optimizer/prompts/v2.0.txt
```
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯æ•™ç¨‹ä½œå®¶ã€‚
è¯·ç¼–å†™ä¸€ä¸ªå…³äºŽ {topic} çš„æ•™ç¨‹ã€‚

è¦æ±‚ï¼š
1. ç»“æž„æ¸…æ™°ï¼ŒåŒ…å«ç®€ä»‹ã€æ­¥éª¤ã€ç¤ºä¾‹ä»£ç 
2. ä»£ç å¯è¿è¡Œï¼Œæœ‰è¯¦ç»†æ³¨é‡Š
3. è¯­è¨€ç®€æ´ï¼Œé¿å…å†—é•¿
4. åŒ…å«å®žé™…åº”ç”¨åœºæ™¯

æ•™ç¨‹é•¿åº¦ï¼š{word_count} å­—å·¦å³
```

## ðŸ“ ç›®å½•ç»“æž„

```
/workspace/subagents/{agent_id}/optimizer/
â”œâ”€â”€ config.json              # ä¼˜åŒ–é…ç½®
â”œâ”€â”€ trajectories.jsonl       # æ‰§è¡Œè½¨è¿¹è®°å½•
â”œâ”€â”€ rewards.jsonl            # å¥–åŠ±ä¿¡å·è®°å½•
â”œâ”€â”€ optimization_report.json # ä¼˜åŒ–åˆ†æžæŠ¥å‘Š
â”œâ”€â”€ prompts/                 # æç¤ºè¯ç‰ˆæœ¬ç›®å½•
â”‚   â”œâ”€â”€ v1.0.txt
â”‚   â”œâ”€â”€ v1.1.txt
â”‚   â””â”€â”€ v2.0.txt
â””â”€â”€ scripts/                 # åˆ†æžè„šæœ¬
    â”œâ”€â”€ analyze_trends.py
    â”œâ”€â”€ ab_test.py
    â””â”€â”€ generate_report.py
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **éšç§ä¿æŠ¤**: è½¨è¿¹æ•°æ®å¯èƒ½åŒ…å«æ•æ„Ÿä¿¡æ¯ï¼Œæ³¨æ„è„±æ•
2. **å­˜å‚¨ç®¡ç†**: å®šæœŸæ¸…ç†æ—§è½¨è¿¹æ•°æ®ï¼Œé¿å…æ–‡ä»¶è¿‡å¤§
3. **å¥–åŠ±è®¾è®¡**: å¥–åŠ±å‡½æ•°è¦åˆç†ï¼Œé¿å…ä¼˜åŒ–é”™æ–¹å‘
4. **ç‰ˆæœ¬æŽ§åˆ¶**: æç¤ºè¯ç‰ˆæœ¬è¦è®°å½•æ¸…æ™°ï¼Œæ–¹ä¾¿å›žæ»š

## ðŸŽ¯ ä¸Ž Agent Lightning å¯¹æ¯”

| åŠŸèƒ½ | Agent Lightning | Agent Optimizer |
|------|----------------|-----------------|
| å®‰è£…å¤æ‚åº¦ | éœ€è¦ pip å®‰è£… | âœ… é›¶å®‰è£… |
| ä¾èµ– | Python åŒ…ä¾èµ– | âœ… æ— ä¾èµ– |
| RL è®­ç»ƒ | âœ… å®Œæ•´ RL æ”¯æŒ | åŸºç¡€å¥–åŠ±åé¦ˆ |
| æç¤ºè¯ä¼˜åŒ– | âœ… è‡ªåŠ¨ä¼˜åŒ– | âœ… æ‰‹åŠ¨+A/B æµ‹è¯• |
| é›†æˆéš¾åº¦ | ä¸­ç­‰ | âœ… ç®€å• |
| é€‚ç”¨åœºæ™¯ | å¤§è§„æ¨¡è®­ç»ƒ | âœ… è½»é‡çº§æŒç»­ä¼˜åŒ– |

## ðŸš€ æœªæ¥æ‰©å±•

- [ ] è‡ªåŠ¨åŒ–æç¤ºè¯ä¼˜åŒ–ç®—æ³•
- [ ] é›†æˆç®€å• RL ç®—æ³•ï¼ˆå¦‚ Banditï¼‰
- [ ] Web Dashboard å¯è§†åŒ–
- [ ] å¤š Agent ååŒä¼˜åŒ–
- [ ] å¥–åŠ±å‡½æ•°æ¨¡æ¿åº“

---

*Agent Optimizer - V6.1 åŽŸç”Ÿæ€§èƒ½ä¼˜åŒ–æ¡†æž¶*
