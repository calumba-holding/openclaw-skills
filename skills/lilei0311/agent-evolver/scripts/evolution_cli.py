#!/usr/bin/env python3
"""
Evolution CLI - å‘½ä»¤è¡Œå·¥å…·
æä¾›æ˜“ç”¨çš„å‘½ä»¤è¡Œæ¥å£æ¥æ“ä½œè‡ªè¿›åŒ–å¼•æ“
"""

import argparse
import json
import sys
import os
from pathlib import Path

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from evolver_core import EvolutionManager, ExperienceStore, LLMIntegration
from experience_vectorizer import ExperienceVectorizer


def cmd_evolve(args):
    """æ‰§è¡Œè¿›åŒ–å‘¨æœŸ"""
    evolver = EvolutionManager(agent_id=args.agent_id)
    
    result = evolver.run_evolution(
        task_input=args.input,
        task_type=args.task_type
    )
    
    if args.json:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print(f"ä»»åŠ¡ç±»å‹: {result['task_type']}")
        print(f"æ‰§è¡ŒçŠ¶æ€: {result['execute_result']['status']}")
        print(f"ç­–ç•¥æ›´æ–°: {'æ˜¯' if result['strategy_updated'] else 'å¦'}")
        
        if result['experience'].get('solution'):
            print(f"\nè§£å†³æ–¹æ¡ˆ: {result['experience']['solution']}")


def cmd_analyze(args):
    """åˆ†ææ‰§è¡Œç»“æœ"""
    llm = LLMIntegration()
    store = ExperienceStore()
    
    if args.result_file:
        with open(args.result_file, 'r') as f:
            result_data = json.load(f)
    else:
        result_data = {"error": args.result}
    
    error_info = {
        "error_type": result_data.get("error", {}).get("type", "Unknown"),
        "error_message": result_data.get("error", {}).get("message", args.result),
        "task_type": result_data.get("task_type", "general"),
        "trigger_input": result_data.get("input", "")
    }
    
    analysis = llm.analyze_error(error_info, result_data.get("context", {}))
    
    if args.json:
        print(json.dumps(analysis, indent=2, ensure_ascii=False))
    else:
        print("=== é”™è¯¯åˆ†æ ===")
        print(f"åŸå› : {analysis['analysis']}")
        print(f"\nè§£å†³æ–¹æ¡ˆ: {analysis['solution']}")
        print(f"\nç­–ç•¥ä¼˜åŒ–: {analysis['strategy_delta']}")
        print(f"\nå…³é”®è¯: {', '.join(analysis['keywords'])}")


def cmd_search(args):
    """æœç´¢ç›¸ä¼¼ç»éªŒ"""
    store = ExperienceStore()
    vectorizer = ExperienceVectorizer()
    
    if vectorizer.vector_store:
        results = vectorizer.search_similar_experiences(args.query, args.limit)
        
        if args.json:
            output = []
            for r in results:
                exp = store.get_experience(r.experience_id)
                if exp:
                    output.append({
                        "similarity": r.similarity,
                        "experience": exp.__dict__ if hasattr(exp, '__dict__') else exp
                    })
            print(json.dumps(output, indent=2, ensure_ascii=False))
        else:
            print(f"æ‰¾åˆ° {len(results)} æ¡ç›¸ä¼¼ç»éªŒ:\n")
            for i, r in enumerate(results, 1):
                exp = store.get_experience(r.experience_id)
                if exp:
                    print(f"{i}. ç›¸ä¼¼åº¦: {r.similarity:.2%}")
                    print(f"   é”™è¯¯ç±»å‹: {exp.error_type}")
                    print(f"   è§£å†³æ–¹æ¡ˆ: {exp.solution}")
                    print()
    else:
        experiences = store.query_experiences(limit=args.limit * 2)
        
        results = []
        query_lower = args.query.lower()
        
        for exp in experiences:
            score = 0
            for keyword in exp.keywords:
                if keyword.lower() in query_lower:
                    score += 1
            
            if exp.error_message and exp.error_message.lower() in query_lower:
                score += 2
            
            if score > 0:
                results.append({
                    "experience": exp,
                    "similarity": score / (len(exp.keywords) + 2)
                })
        
        results.sort(key=lambda x: x["similarity"], reverse=True)
        results = results[:args.limit]
        
        if args.json:
            output = []
            for r in results:
                output.append({
                    "similarity": r["similarity"],
                    "experience": r["experience"].__dict__ if hasattr(r["experience"], '__dict__') else r["experience"]
                })
            print(json.dumps(output, indent=2, ensure_ascii=False))
        else:
            print(f"æ‰¾åˆ° {len(results)} æ¡ç›¸ä¼¼ç»éªŒ:\n")
            for i, r in enumerate(results, 1):
                exp = r["experience"]
                print(f"{i}. ç›¸ä¼¼åº¦: {r['similarity']:.2%}")
                print(f"   é”™è¯¯ç±»å‹: {exp.error_type}")
                print(f"   è§£å†³æ–¹æ¡ˆ: {exp.solution}")
                print()


def cmd_stats(args):
    """æŸ¥çœ‹è¿›åŒ–ç»Ÿè®¡"""
    store = ExperienceStore()
    vectorizer = ExperienceVectorizer()
    
    stats = store.get_stats(args.agent_id)
    vector_stats = vectorizer.get_collection_stats()
    
    result = {
        **stats,
        "vector_search": vector_stats
    }
    
    if args.json:
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        print("=== è¿›åŒ–ç»Ÿè®¡ ===\n")
        print(f"æ€»ç»éªŒæ•°: {stats['total_experiences']}")
        print(f"æˆåŠŸæ¬¡æ•°: {stats['success_count']}")
        print(f"å¤±è´¥æ¬¡æ•°: {stats['failed_count']}")
        print(f"æ”¹è¿›æ¬¡æ•°: {stats['improved_count']}")
        print(f"æˆåŠŸç‡: {stats['success_rate']:.2%}")
        print(f"æ”¹è¿›ç‡: {stats['improvement_rate']:.2%}")
        print(f"\nä»»åŠ¡ç±»å‹: {', '.join(stats['task_types'])}")
        print(f"é”™è¯¯ç±»å‹: {', '.join(stats['error_types'])}")
        print(f"\nå‘é‡æœç´¢: {'å·²å¯ç”¨' if vector_stats['enabled'] else 'æœªå¯ç”¨'}")
        if vector_stats['enabled']:
            print(f"å‘é‡æ•°é‡: {vector_stats['count']}")


def cmd_history(args):
    """æŸ¥çœ‹è¿›åŒ–å†å²"""
    store = ExperienceStore()
    
    experiences = store.query_experiences(
        task_type=args.task_type,
        error_type=args.error_type,
        limit=args.limit
    )
    
    if args.json:
        output = [exp.__dict__ if hasattr(exp, '__dict__') else exp for exp in experiences]
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(f"=== è¿›åŒ–å†å² (æœ€è¿‘ {len(experiences)} æ¡) ===\n")
        
        for i, exp in enumerate(experiences, 1):
            status_icon = "âœ…" if exp.status == "success" else "âŒ" if exp.status == "failed" else "ğŸ”„"
            
            print(f"{i}. {status_icon} [{exp.task_type}] {exp.error_type}")
            print(f"   æ—¶é—´: {exp.created_at}")
            print(f"   è§£å†³æ–¹æ¡ˆ: {exp.solution[:50]}..." if len(exp.solution) > 50 else f"   è§£å†³æ–¹æ¡ˆ: {exp.solution}")
            print()


def cmd_export(args):
    """å¯¼å‡ºç»éªŒåº“"""
    store = ExperienceStore()
    
    experiences = store.query_experiences(limit=10000)
    
    output = {
        "export_time": __import__('datetime').datetime.now().isoformat(),
        "stats": store.get_stats(),
        "experiences": [exp.__dict__ if hasattr(exp, '__dict__') else exp for exp in experiences]
    }
    
    with open(args.output, 'w') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"å·²å¯¼å‡º {len(experiences)} æ¡ç»éªŒåˆ° {args.output}")


def main():
    parser = argparse.ArgumentParser(
        description="Agent Evolver CLI - AI Agent è‡ªè¿›åŒ–å¼•æ“å‘½ä»¤è¡Œå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")
    
    evolve_parser = subparsers.add_parser("evolve", help="æ‰§è¡Œè¿›åŒ–å‘¨æœŸ")
    evolve_parser.add_argument("input", help="ä»»åŠ¡è¾“å…¥")
    evolve_parser.add_argument("--agent-id", default="default", help="Agent ID")
    evolve_parser.add_argument("--task-type", default="general", help="ä»»åŠ¡ç±»å‹")
    evolve_parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    
    analyze_parser = subparsers.add_parser("analyze", help="åˆ†ææ‰§è¡Œç»“æœ")
    analyze_parser.add_argument("result", nargs="?", help="æ‰§è¡Œç»“æœ")
    analyze_parser.add_argument("--result-file", help="ç»“æœæ–‡ä»¶è·¯å¾„")
    analyze_parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    
    search_parser = subparsers.add_parser("search", help="æœç´¢ç›¸ä¼¼ç»éªŒ")
    search_parser.add_argument("query", help="æœç´¢æŸ¥è¯¢")
    search_parser.add_argument("--limit", type=int, default=5, help="ç»“æœæ•°é‡")
    search_parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    
    stats_parser = subparsers.add_parser("stats", help="æŸ¥çœ‹è¿›åŒ–ç»Ÿè®¡")
    stats_parser.add_argument("--agent-id", help="Agent ID")
    stats_parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    
    history_parser = subparsers.add_parser("history", help="æŸ¥çœ‹è¿›åŒ–å†å²")
    history_parser.add_argument("--limit", type=int, default=10, help="æ˜¾ç¤ºæ•°é‡")
    history_parser.add_argument("--task-type", help="ä»»åŠ¡ç±»å‹è¿‡æ»¤")
    history_parser.add_argument("--error-type", help="é”™è¯¯ç±»å‹è¿‡æ»¤")
    history_parser.add_argument("--json", action="store_true", help="JSON è¾“å‡º")
    
    export_parser = subparsers.add_parser("export", help="å¯¼å‡ºç»éªŒåº“")
    export_parser.add_argument("output", help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    if args.command == "evolve":
        cmd_evolve(args)
    elif args.command == "analyze":
        cmd_analyze(args)
    elif args.command == "search":
        cmd_search(args)
    elif args.command == "stats":
        cmd_stats(args)
    elif args.command == "history":
        cmd_history(args)
    elif args.command == "export":
        cmd_export(args)
    else:
        parser.print_help()


if __name__ == "__main__":
    main()
